
```{python}
# | label: char-similar

from pathlib import Path
from tqdm import tqdm
from itertools import combinations
import numpy as np
import pandas as pd
from char_similar import pool_cal_sim


def calc_sim_word(w1, w2):
    sim_list = [pool_cal_sim(w_i, w_j) for w_i in w1 for w_j in w2]
    return np.average(sim_list, weights=[1, 0.5, 0.5, 1])


path_words = Path("data") / "stimuli" / "words_list.tsv"
words_used = range(150)
words = pd.read_csv(path_words, sep="\t")["word"][words_used].to_numpy()
pairs = list(combinations(words_used, 2))
rows = []
for i, j in tqdm(pairs, desc="computing similarities", leave=True):
    sim = calc_sim_word(words[i], words[j])
    rows.append(
        {
            "word_id1": i + 1,
            "word_id2": j + 1,
            "word1": words[i],
            "word2": words[j],
            "similarity": sim,
        }
    )
sim_scores = pd.DataFrame(rows)

path_sims = Path("data") / "stimuli" / "word_shape_sims" / "char_similar.tsv"
sim_scores.to_csv(path_sims, sep="\t", index=False)
```

```{python}
# | label: alexnet

from pathlib import Path
import numpy as np
import pandas as pd
from tqdm import tqdm
from torchvision.models import alexnet, AlexNet_Weights
import torchlens as tl
from PIL import Image


def extract_features_alexnet(img_path, model, preprocess, layers_to_save):
    """
    使用预训练的 AlexNet 提取图像特征。
    """
    img = Image.open(img_path).convert("RGB")
    x = preprocess(img).unsqueeze(0)  # 添加 batch 维度
    model_history = tl.log_forward_pass(
        model,
        x,
        layers_to_save=layers_to_save,
        vis_opt="none",
    )
    return model_history


def calc_similarity(model_histories, layer_name):
    """
    计算指定层的特征相似性。
    """
    vectors = []
    for model_history in model_histories:
        tensor = model_history[layer_name].tensor_contents
        vec = tensor.flatten().detach().numpy()
        vectors.append(vec)

    X = np.stack(vectors, axis=0)
    return np.corrcoef(X)


# Load model globbally to avoid reloading for each image
weights = AlexNet_Weights.DEFAULT
model = alexnet(weights=weights).eval()
preprocess = weights.transforms()
layers = [
    "conv2d_1_1",
    "conv2d_2_4",
    "conv2d_3_7",
    "conv2d_4_9",
    "conv2d_5_11",
    "linear_1_17",
    "linear_2_20",
    "linear_3_22",
]

path_images = Path("data") / "stimuli" / "images"
files_images = list(path_images.glob("*.JPG"))
model_histories = []
for file_image in tqdm(files_images, desc="Processing images", leave=True):
    model_history = extract_features_alexnet(
        file_image, model, preprocess, layers_to_save=layers
    )
    model_histories.append(model_history)


similarities = {}
for layer in tqdm(layers, desc="Calculating similarities", leave=True):
    similarity = calc_similarity(model_histories, layer)
    labels = [f"{i + 1}" for i in range(similarity.shape[0])]
    df_similarity = pd.DataFrame(similarity, index=labels, columns=labels)
    long_df = df_similarity.stack().reset_index()
    long_df.columns = ["image_id1", "image_id2", "similarity"]
    similarities[layer] = long_df

# stack all layers into a single DataFrame
similarities = pd.concat(
    [df.assign(layer=layer) for layer, df in similarities.items()],
    ignore_index=True,
)

# save to a tsv file
path_sims = Path("data") / "stimuli" / "word_shape_sims" / "alexnet.tsv"
similarities.to_csv(path_sims, sep="\t", index=False)
```
